{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üê´ CAMEL Task Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this tutorial, we will focus on demonstrating how to use the task module in the CAMEL framework. We will guide you through creating, evolving, and decomposing tasks to illustrate how the task module can be utilized for efficient task management in agent-based systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sections included:\n",
    "\n",
    "- Setting up a ChatAgent with the CAMEL framework\n",
    "- Creating a Task and evolving it with the agent\n",
    "- Task decomposition using TaskManager\n",
    "\n",
    "Let's go step by step!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import necessary CAMEL modules\n",
    "\n",
    "First, we need to import the required CAMEL modules for creating the ChatAgent and handling tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.agents import ChatAgent\n",
    "from camel.configs import ChatGPTConfig\n",
    "from camel.messages import BaseMessage\n",
    "from camel.models import ModelFactory\n",
    "from camel.tasks import (\n",
    "    Task,\n",
    "    TaskManager,\n",
    ")\n",
    "from camel.types import (\n",
    "    ModelPlatformType,\n",
    "    ModelType,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set up the Large Language Model (LLM)\n",
    "\n",
    "Next, we set up the model configuration. We are using a CAMEL LLM (GPT-4O Mini in this case) for our assistant agent. The configuration is designed to ensure the agent‚Äôs behavior remains deterministic by setting temperature=0.0, meaning no randomness will be introduced in the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration for the assistant\n",
    "assistant_model_config = ChatGPTConfig(\n",
    "    temperature=0.0,  # Set to 0 for deterministic output\n",
    ")\n",
    "\n",
    "# Create the model using the configuration\n",
    "model = ModelFactory.create(\n",
    "    model_platform=ModelPlatformType.OPENAI,\n",
    "    model_type=ModelType.GPT_4O_MINI,\n",
    "    model_config_dict=assistant_model_config.as_dict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize the ChatAgent\n",
    "\n",
    "We now create a ChatAgent using the previously defined model. The purpose of this agent is to interact with tasks created in the CAMEL framework, helping us demonstrate how to create, evolve, and decompose tasks using the task module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the assistant's system message\n",
    "assistant_sys_msg = BaseMessage.make_user_message(\n",
    "    role_name=\"Teacher\",\n",
    "    content=(\"You are a personal math tutor and programmer.\"),\n",
    ")\n",
    "\n",
    "# Initialize the ChatAgent\n",
    "agent = ChatAgent(assistant_sys_msg, model)\n",
    "agent.reset()  # Reset the agent's internal state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evolve and decompose tasks\n",
    "\n",
    "We now create a Task that represents a math problem for the assistant to solve. In this case, we are asking the assistant to calculate how much Weng earned for babysitting based on her hourly rate and the time she worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Task for the agent to solve\n",
    "task = Task(\n",
    "    content=\"Weng earns $12 an hour for babysitting. Yesterday, she just did 51 minutes of babysitting. How much did she earn?\",\n",
    "    id=\"0\",  # Task identifier\n",
    ")\n",
    "\n",
    "# Print the task to see the original form\n",
    "print(task.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolve the Task\n",
    "\n",
    "We can evolve the task using the TaskManager, which allows the agent to potentially update or reframe the task based on its internal logic and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_manager = TaskManager(task)\n",
    "\n",
    "evolved_task = task_manager.evolve(task, agent=agent)\n",
    "if evolved_task is not None:\n",
    "    print(evolved_task.to_string())\n",
    "else:\n",
    "    print(\"Evolved task is None.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decompose the Task\n",
    "\n",
    "Sometimes, tasks are complex and need to be broken down into smaller subtasks. We use decompose() to allow the agent to split the original task into simpler parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tasks = task.decompose(agent=agent)\n",
    "for t in new_tasks:\n",
    "    print(t.to_string())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
