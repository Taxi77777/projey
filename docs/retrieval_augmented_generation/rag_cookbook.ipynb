{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Cookbook\n",
    "\n",
    "In this notebook, we show the useage of CAMEL `RetrievalModule` in both customized way and default atuto way. We will also show how to combine `RetrievalModule` with `RolePlaying` by using `FunctionCalling`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Let's first load the CAMEL paper from https://arxiv.org/pdf/2303.17760.pdf. This will be our local example data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-06 20:35:34--  https://arxiv.org/pdf/2303.17760.pdf\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.195.42, 151.101.3.42, 151.101.67.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.195.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7536497 (7.2M) [application/pdf]\n",
      "Saving to: ‘local_data/camel paper2.pdf’\n",
      "\n",
      "local_data/camel pa 100%[===================>]   7.19M  31.6KB/s    in 4m 15s  \n",
      "\n",
      "2024-01-06 20:39:59 (28.9 KB/s) - ‘local_data/camel paper2.pdf’ saved [7536497/7536497]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'local_data/'\n",
    "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2303.17760.pdf\" -O \"local_data/camel paper.pdf\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Customized RAG\n",
    "In this section we will set our customized RAG pipeline.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set embedding model, we will use `OpenAIEmbedding` as the embedding model, so we need to set the `OPENAI_API_KEY` in below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] =\"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\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and set the embedding instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.embeddings import OpenAIEmbedding\n",
    "\n",
    "embedding_model_instance = OpenAIEmbedding()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and set the vector storage instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.storages.vectordb_storages import QdrantStorage\n",
    "\n",
    "vector_storage_instance=QdrantStorage(\n",
    "            vector_dim=embedding_model_instance.get_output_dim(), collection=\"my first collection\",\n",
    "            create_collection=True, # set this as ture to create the collection for first running\n",
    "            path=\"storage_customized_run\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and set the retrieval instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.functions.retrieval_function import RetrievalModule\n",
    "\n",
    "retrieval_instance = RetrievalModule(embedding_model=embedding_model_instance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use integrated `Unstructured Moudle` to splite the content into small chunks, the content will be splited automacitlly with its `chunk_by_title` function, the max character for each chunk is 500 characters, which is a suitable length for `OpenAIEmbedding`. All the text in the chunks will be embed and stored to the vector storgae instance, it will take some time, please wait.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enrei/Library/Caches/pypoetry/virtualenvs/camel-ai-WbV-SHy3-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "retrieval_instance.embed_and_store_chunks(content_input_path=\"local_data/camel paper.pdf\",vector_storage=vector_storage_instance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can retrieve information from the vector storage by giving a query. By default it will give you back the text content from top 1 chunk with highest Cosine similarity, and the similarity should be higher than 0.75 to ensure the retrieved text content is relevant to the query. You can also change the `top_k` value and `similarity_threshold` value with your needs.\n",
    "\n",
    "The returned string list includes:\n",
    "- similarity score\n",
    "- content path\n",
    "- metadata\n",
    "- text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'similarity score': '0.8369745249499829', 'content path': 'local_data/camel paper.pdf', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'last_modified': '2024-01-06T17:16:57', 'page_number': 1}, 'text': 'CAMEL: Communicative Agents for “Mind” Exploration of Large Scale Language Model Society\\n\\nhttps://www.camel-ai.org\\n\\nGuohao Li⇤ Hasan Abed Al Kader Hammoud*\\n\\nHani Itani*\\n\\nDmitrii Khizbullin\\n\\nBernard Ghanem\\n\\nKing Abdullah University of Science and Technology (KAUST)\\n\\nAbstract'}\n",
      "{'similarity score': '0.8077271901798347', 'content path': 'local_data/camel paper.pdf', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'last_modified': '2024-01-06T17:16:57', 'page_number': 1}, 'text': 'rk, offering a scalable approach for studying the cooperative behaviors and capabilities of multi-agent systems, and open-sourcing our library to support research on communicative agents and beyond. The GitHub repository of this project is made publicly available on: https://github.com/lightaime/camel.'}\n"
     ]
    }
   ],
   "source": [
    "retrieved_info=retrieval_instance.query_and_compile_results(query=\"What is CAMEL?\",vector_storage=vector_storage_instance,top_k=2)\n",
    "\n",
    "print(retrieved_info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try an irrelevant query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No suitable information retrieved from local_data/camel paper.pdf with similarity_throthold = 0.75.\n"
     ]
    }
   ],
   "source": [
    "retrieved_info_irrevelant=retrieval_instance.query_and_compile_results(query=\"Compared with dumpling and rice, which should I take for dinner?\",vector_storage=vector_storage_instance,top_k=2)\n",
    "\n",
    "print(retrieved_info_irrevelant)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Default RAG\n",
    "In this section we will run the auto RAG pipeline with default settings. It uses `OpenAIEmbedding` as default embedding model and `Qdrant` as default vector storage.\n",
    "\n",
    "What you need to do is:\n",
    "- Set content input paths, which can be local paths or remote urls\n",
    "- Set local storage path or remote url and api key for Qdrant\n",
    "- Give a query\n",
    "\n",
    "The default RAG pipeline would create collections for given content input paths, the collection name will be set automaticlly based on the content input path name, if the collection exists, it will do the retrieval directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Query:\n",
      "{What is CAMEL-AI}\n",
      "Retrieved Context:\n",
      "\n",
      "{'similarity score': '0.8322398642543604', 'content path': 'local_data/camel paper.pdf', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'last_modified': '2024-01-06T17:16:57', 'page_number': 1}, 'text': 'CAMEL: Communicative Agents for “Mind” Exploration of Large Scale Language Model Society\\n\\nhttps://www.camel-ai.org\\n\\nGuohao Li⇤ Hasan Abed Al Kader Hammoud*\\n\\nHani Itani*\\n\\nDmitrii Khizbullin\\n\\nBernard Ghanem\\n\\nKing Abdullah University of Science and Technology (KAUST)\\n\\nAbstract'}\n",
      "{'similarity score': '0.8380730666554639', 'content path': 'https://www.camel-ai.org/', 'metadata': {'emphasized_text_contents': ['Mission', 'CAMEL-AI.org', 'is an open-source community dedicated to the study of autonomous and communicative agents. We believe that studying these agents on a large scale offers valuable insights into their behaviors, capabilities, and potential risks. To facilitate research in this field, we provide, implement, and support various types of agents, tasks, prompts, models, datasets, and simulated environments.', 'Join us via', 'Slack', 'Discord', 'or'], 'emphasized_text_tags': ['span', 'span', 'span', 'span', 'span', 'span', 'span'], 'filetype': 'text/html', 'languages': ['eng'], 'link_texts': [None, None, None], 'link_urls': ['#h.3f4tphhd9pn8', 'https://join.slack.com/t/camel-ai/shared_invite/zt-1vy8u9lbo-ZQmhIAyWSEfSwLCl2r2eKA', 'https://discord.gg/CNcNpquyDc'], 'page_number': 1, 'url': 'https://www.camel-ai.org/'}, 'text': 'Mission\\n\\nCAMEL-AI.org is an open-source community dedicated to the study of autonomous and communicative agents. We believe that studying these agents on a large scale offers valuable insights into their behaviors, capabilities, and potential risks. To facilitate research in this field, we provide, implement, and support various types of agents, tasks, prompts, models, datasets, and simulated environments.\\n\\nJoin us via\\n\\nSlack\\n\\nDiscord\\n\\nor'}\n"
     ]
    }
   ],
   "source": [
    "retrieval_instance_default = RetrievalModule()\n",
    "retrieved_info = retrieval_instance_default.run_default_retrieval(content_input_paths=[\n",
    "        \"local_data/camel paper.pdf\", # example local path\n",
    "        \"https://www.camel-ai.org/\", # example remote url\n",
    "    ], vector_storage_local_path=\"storage_default_run\",\n",
    "    query=\"What is CAMEL-AI\")\n",
    "\n",
    "print(retrieved_info)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Roly-playing with RAG\n",
    "In this section we will show how to combing the default `RetrievalModule` with `RolePlaying` by applying `OpenAI Function Calling`.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to set a retrieval function with well-written docstring for LLM to understand what this function is used for, the main code is the same with the default RAG section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from camel.functions import OpenAIFunction\n",
    "from camel.functions.retrieval_function import RetrievalModule\n",
    "\n",
    "def local_retrieval(query: str) -> str:\n",
    "    r\"\"\"Performs a default local retrieval for information. Given a query,\n",
    "    this function will retrieve the information from the local vector storage,\n",
    "    and return the retrieved information back. It is useful for information\n",
    "    retrieval.\n",
    "\n",
    "    Args:\n",
    "        query (string): Question you want to be answered.\n",
    "\n",
    "    Returns:\n",
    "        str: Aggregated information retrieved in response to the query.\n",
    "\n",
    "    Example:\n",
    "        local_retrieval(query = \"what is camel?\")\n",
    "    \"\"\"\n",
    "    retrieval_instance = RetrievalModule()\n",
    "    retrieved_info = retrieval_instance.run_default_retrieval( content_input_paths=[\n",
    "            \"local_data/camel paper.pdf\",\n",
    "            \"https://www.camel-ai.org/\",\n",
    "        ],\n",
    "        vector_storage_local_path=\"storage_default_run\",\n",
    "        query=query)\n",
    "    return retrieved_info\n",
    "\n",
    "# add the function to OpenAIFunction list\n",
    "RETRIEVAL_FUNCS: List[OpenAIFunction] = [\n",
    "    OpenAIFunction(func)\n",
    "    for func in [\n",
    "        local_retrieval,\n",
    "        ]\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the role-playing with defined retrieval function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAI Assistant sys message:\n",
      "BaseMessage(role_name='Searcher', role_type=<RoleType.ASSISTANT: 'assistant'>, meta_dict={'task': \"What is Role-playing Framework, how many assistant roles did camel use, what's the value plus 100?\", 'assistant_role': 'Searcher', 'user_role': 'Professor'}, content=\"===== RULES OF ASSISTANT =====\\nNever forget you are a Searcher and I am a Professor. Never flip roles! Never instruct me!\\nWe share a common interest in collaborating to successfully complete a task.\\nYou must help me to complete the task.\\nHere is the task: What is Role-playing Framework, how many assistant roles did camel use, what's the value plus 100?. Never forget our task!\\nI must instruct you based on your expertise and my needs to complete the task.\\n\\nI must give you one instruction at a time.\\nYou must write a specific solution that appropriately solves the requested instruction and explain your solutions.\\nYou must decline my instruction honestly if you cannot perform the instruction due to physical, moral, legal reasons or your capability and explain the reasons.\\nUnless I say the task is completed, you should always start with:\\n\\nSolution: <YOUR_SOLUTION>\\n\\n<YOUR_SOLUTION> should be very specific, include detailed explanations and provide preferable detailed implementations and examples and lists for task-solving.\\nAlways end <YOUR_SOLUTION> with: Next request.\")\n",
      "\n",
      "\u001b[34mAI User sys message:\n",
      "BaseMessage(role_name='Professor', role_type=<RoleType.USER: 'user'>, meta_dict={'task': \"What is Role-playing Framework, how many assistant roles did camel use, what's the value plus 100?\", 'assistant_role': 'Searcher', 'user_role': 'Professor'}, content='===== RULES OF USER =====\\nNever forget you are a Professor and I am a Searcher. Never flip roles! You will always instruct me.\\nWe share a common interest in collaborating to successfully complete a task.\\nI must help you to complete the task.\\nHere is the task: What is Role-playing Framework, how many assistant roles did camel use, what\\'s the value plus 100?. Never forget our task!\\nYou must instruct me based on my expertise and your needs to solve the task ONLY in the following two ways:\\n\\n1. Instruct with a necessary input:\\nInstruction: <YOUR_INSTRUCTION>\\nInput: <YOUR_INPUT>\\n\\n2. Instruct without any input:\\nInstruction: <YOUR_INSTRUCTION>\\nInput: None\\n\\nThe \"Instruction\" describes a task or question. The paired \"Input\" provides further context or information for the requested \"Instruction\".\\n\\nYou must give me one instruction at a time.\\nI must write a response that appropriately solves the requested instruction.\\nI must decline your instruction honestly if I cannot perform the instruction due to physical, moral, legal reasons or my capability and explain the reasons.\\nYou should instruct me not ask me questions.\\nNow you must start to instruct me using the two ways described above.\\nDo not add anything else other than your instruction and the optional corresponding input!\\nKeep giving me instructions and necessary inputs until you think the task is completed.\\nWhen the task is completed, you must only reply with a single word <CAMEL_TASK_DONE>.\\nNever say <CAMEL_TASK_DONE> unless my responses have solved your task.')\n",
      "\n",
      "\u001b[33mOriginal task prompt:\n",
      "What is Role-playing Framework, how many assistant roles did camel use, what's the value plus 100?\n",
      "\n",
      "\u001b[36mSpecified task prompt:\n",
      "None\n",
      "\n",
      "\u001b[31mFinal task prompt:\n",
      "What is Role-playing Framework, how many assistant roles did camel use, what's the value plus 100?\n",
      "\n",
      "\u001b[34mAI User:\n",
      "\n",
      "Instruction: Explain the concept of a Role-playing Framework.\n",
      "Input: None\n",
      "\n",
      "\n",
      "\u001b[32mAI Assistant:\n",
      "\n",
      "Solution: A Role-playing Framework is a structured system used to facilitate role-playing activities, often within the context of games, simulations, or training exercises. It provides a set of rules, guidelines, and mechanisms that define how participants can interact with each other and the environment within the role-playing scenario.\n",
      "\n",
      "The framework typically includes:\n",
      "\n",
      "1. **Character Creation**: Guidelines for creating characters or roles that participants will assume, including attributes, skills, and background stories.\n",
      "\n",
      "2. **Setting**: The environment or world where the role-playing takes place, which can be fictional or based on real-world scenarios.\n",
      "\n",
      "3. **Game Mechanics**: Rules that govern how characters interact with the world and each other, including conflict resolution, skill checks, and the effects of character actions.\n",
      "\n",
      "4. **Narrative Structure**: A storyline or series of events that provides context and objectives for the participants' actions within the role-playing environment.\n",
      "\n",
      "5. **Moderation**: A system for overseeing the role-play, often managed by a game master or facilitator, who ensures that the rules are followed and the narrative progresses coherently.\n",
      "\n",
      "Role-playing Frameworks are used in various contexts, from tabletop role-playing games like Dungeons & Dragons to professional training simulations in fields such as healthcare, law enforcement, and military. They are designed to create immersive experiences that encourage creativity, strategic thinking, and empathy by allowing participants to explore different perspectives and make decisions from within their assumed roles.\n",
      "\n",
      "Next request.\n",
      "\n",
      "\n",
      "\u001b[34mAI User:\n",
      "\n",
      "Instruction: Provide information on how many assistant roles Camel framework uses.\n",
      "Input: None\n",
      "\n",
      "\n",
      "\u001b[32mAI Assistant:\n",
      "\n",
      "Function Execution: local_retrieval\n",
      "\tArgs: {'query': 'how many assistant roles Camel framework uses'}\n",
      "\tResult: Original Query:\n",
      "{how many assistant roles Camel framework uses}\n",
      "Retrieved Context:\n",
      "\n",
      "{'similarity score': '0.7669638100285894', 'content path': 'local_data/camel paper.pdf', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'last_modified': '2024-01-06T17:16:57', 'page_number': 9}, 'text': 'the LLM agent to make the task more speciﬁc. The prompts for assistant role generation, user role generation, and task generation are shown in Figure 4 (AI Society). For our AI society dataset, we generated 50 assistant roles, 50 user roles, and 10 tasks for each combination of roles yielding a total of 25,000 conversations. The generated assistant roles and user roles are shown in Figure 5 (AI Society).'}\n",
      "No suitable information retrieved from https://www.camel-ai.org/ with similarity_throthold = 0.75.\n",
      "\n",
      "Solution: According to the information retrieved from the local data source, the Camel framework generated 50 assistant roles for their AI society dataset. This information was found in a document titled \"camel paper.pdf\" and specifically mentioned on page 9.\n",
      "\n",
      "Next request.\n",
      "\n",
      "\n",
      "\u001b[34mAI User:\n",
      "\n",
      "Instruction: Calculate the value of the assistant roles used by the Camel framework plus 100.\n",
      "Input: None\n",
      "\n",
      "\n",
      "\u001b[32mAI Assistant:\n",
      "\n",
      "Function Execution: add\n",
      "\tArgs: {'a': 50, 'b': 100}\n",
      "\tResult: 150\n",
      "\n",
      "Solution: The value of the assistant roles used by the Camel framework plus 100 is 150.\n",
      "\n",
      "Next request.\n",
      "\n",
      "\n",
      "\u001b[34mAI User:\n",
      "\n",
      "CAMEL_TASK_DONE\n",
      "\n",
      "\n",
      "\u001b[32mAI Assistant:\n",
      "\n",
      "Solution: Understood, the task regarding the Role-playing Framework, the number of assistant roles used by the Camel framework, and the calculated value plus 100 is now completed.\n",
      "\n",
      "Next request.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from camel.societies import role_playing_with_function\n",
    "from camel.functions import MATH_FUNCS # import another function from camel\n",
    "\n",
    "role_playing_with_function(\n",
    "    task_prompt=(\"What is Role-playing Framework, how many assistant roles did camel use, what's the value plus 100?\"),\n",
    "    function_list=[*RETRIEVAL_FUNCS, *MATH_FUNCS]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAMEL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
